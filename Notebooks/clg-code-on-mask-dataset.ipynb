{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\"\"\"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    if len(filenames)!=0:\n        for i in range(2):\n            print(filenames[i])\n    else:\n        pass\"\"\"\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-17T17:09:57.708946Z","iopub.execute_input":"2022-02-17T17:09:57.71125Z","iopub.status.idle":"2022-02-17T17:09:57.756234Z","shell.execute_reply.started":"2022-02-17T17:09:57.711142Z","shell.execute_reply":"2022-02-17T17:09:57.755455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install mediapipe","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:09:57.758121Z","iopub.execute_input":"2022-02-17T17:09:57.758681Z","iopub.status.idle":"2022-02-17T17:10:08.449074Z","shell.execute_reply.started":"2022-02-17T17:09:57.758638Z","shell.execute_reply":"2022-02-17T17:10:08.448279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport keras \nfrom keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Dropout, Input\nfrom keras.preprocessing.image import img_to_array\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm import tqdm \nimport os\nimport re\nimport mediapipe as mp","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:10:08.450661Z","iopub.execute_input":"2022-02-17T17:10:08.450921Z","iopub.status.idle":"2022-02-17T17:10:13.802046Z","shell.execute_reply.started":"2022-02-17T17:10:08.450885Z","shell.execute_reply":"2022-02-17T17:10:13.801236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:10:13.804029Z","iopub.execute_input":"2022-02-17T17:10:13.804284Z","iopub.status.idle":"2022-02-17T17:10:13.812929Z","shell.execute_reply.started":"2022-02-17T17:10:13.804249Z","shell.execute_reply":"2022-02-17T17:10:13.812263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize mediapipe \nmp_selfie_segmentation = mp.solutions.selfie_segmentation\nselfie_segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)\n\nbg_image = cv2.imread(\"../input/blank-img/blank.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:10:13.81411Z","iopub.execute_input":"2022-02-17T17:10:13.814792Z","iopub.status.idle":"2022-02-17T17:10:13.862615Z","shell.execute_reply.started":"2022-02-17T17:10:13.814754Z","shell.execute_reply":"2022-02-17T17:10:13.860856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_background(img):\n    frame = cv2.flip(img, 1)\n    height , width, channel = frame.shape\n\n    RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n    # get the result \n    results = selfie_segmentation.process(RGB)\n\n    # extract segmented mask\n    mask = results.segmentation_mask\n\n    # it returns true or false where the condition applies in the mask\n    condition = np.stack(\n      (results.segmentation_mask,) * 3, axis=-1) > 0.6\n    \n    bg_image = cv2.imread(\"../input/blank-img/blank.jpg\")\n    # resize the background image to the same size of the original frame\n    bg_image = cv2.resize(bg_image, (width, height))\n\n    # combine frame and background image using the condition\n    output_image = np.where(condition, frame, bg_image)\n\n    return output_image\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:10:13.864029Z","iopub.execute_input":"2022-02-17T17:10:13.864268Z","iopub.status.idle":"2022-02-17T17:10:13.87303Z","shell.execute_reply.started":"2022-02-17T17:10:13.864234Z","shell.execute_reply":"2022-02-17T17:10:13.872254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"photo=\"../input/blank-img/seed0014.png\"\nimg=cv2.imread(photo)\nimg = remove_background(img)\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:10:13.874665Z","iopub.execute_input":"2022-02-17T17:10:13.875384Z","iopub.status.idle":"2022-02-17T17:10:14.198919Z","shell.execute_reply.started":"2022-02-17T17:10:13.87534Z","shell.execute_reply":"2022-02-17T17:10:14.198247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def img2sketch(photo, k_size):\n    #Read Image\n    img=cv2.imread(photo)\n    \n    img = remove_background(img)\n    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    # Convert to Grey Image\n    grey_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n    # Invert Image\n    invert_img=cv2.bitwise_not(grey_img)\n    #invert_img=255-grey_img\n\n    # Blur image\n    blur_img=cv2.GaussianBlur(invert_img, (k_size,k_size),0)\n\n    # Invert Blurred Image\n    invblur_img=cv2.bitwise_not(blur_img)\n    #invblur_img=255-blur_img\n\n    # Sketch Image\n    sketch_img=cv2.divide(grey_img,invblur_img, scale=256.0)\n\n    # Save Sketch \n    #cv2.imwrite('sketch.png', sketch_img)\n    return sketch_img\n    # Display sketch\n    #plt.imshow(sketch_img)\n    \n#Function call\n#img2sketch(photo='../input/celeba-dataset/img_align_celeba/img_align_celeba/000022.jpg', k_size=7)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:10:14.20011Z","iopub.execute_input":"2022-02-17T17:10:14.200505Z","iopub.status.idle":"2022-02-17T17:10:14.208072Z","shell.execute_reply.started":"2022-02-17T17:10:14.200453Z","shell.execute_reply":"2022-02-17T17:10:14.207388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array = []\nsketch_array = []\nlimit=2472\nSIZE=256\n# 2472\n#count=0\n\nfor dirname, _, filenames in os.walk('../input/face-mask-lite-dataset/without_mask'):\n    \n    if len(filenames)!=0:\n\n        for i in range(1,limit+1):\n\n            file_path=os.path.join(dirname, filenames[i])\n\n            image= cv2.imread(file_path)\n            \n            image=remove_background(image)\n\n            # as opencv load image in bgr format converting it to rgb\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n            # resizing images \n            image = cv2.resize(image, (SIZE, SIZE))\n\n            # normalizing image \n            image = image.astype('float32') / 255.0\n\n            #appending normal normal image    \n            img_array.append(img_to_array(image))\n\n\n    \n  \n        for i in range(1,limit+1):\n\n            file_path=os.path.join(dirname, filenames[i])\n            \n            image=img2sketch(photo=file_path, k_size=7)\n\n            # as opencv load image in bgr format converting it to rgb\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n            # resizing images \n            image = cv2.resize(image, (SIZE, SIZE))\n\n            # normalizing image \n            image = image.astype('float32') / 255.0\n            # appending normal sketch image\n            sketch_array.append(img_to_array(image))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:10:14.209201Z","iopub.execute_input":"2022-02-17T17:10:14.209924Z","iopub.status.idle":"2022-02-17T17:17:03.894851Z","shell.execute_reply.started":"2022-02-17T17:10:14.209885Z","shell.execute_reply":"2022-02-17T17:17:03.894063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(img_array)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:03.898361Z","iopub.execute_input":"2022-02-17T17:17:03.898648Z","iopub.status.idle":"2022-02-17T17:17:03.904229Z","shell.execute_reply.started":"2022-02-17T17:17:03.89859Z","shell.execute_reply":"2022-02-17T17:17:03.903331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sketch_array)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:03.905597Z","iopub.execute_input":"2022-02-17T17:17:03.906108Z","iopub.status.idle":"2022-02-17T17:17:03.916445Z","shell.execute_reply.started":"2022-02-17T17:17:03.906069Z","shell.execute_reply":"2022-02-17T17:17:03.915584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2472\nprint(\"Total number of sketch images:\",len(sketch_array))\nprint(\"Total number of images:\",len(img_array))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:03.918051Z","iopub.execute_input":"2022-02-17T17:17:03.918447Z","iopub.status.idle":"2022-02-17T17:17:03.925586Z","shell.execute_reply.started":"2022-02-17T17:17:03.918407Z","shell.execute_reply":"2022-02-17T17:17:03.924787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining function to plot images pair\ndef plot_images(image, sketches):\n    plt.figure(figsize=(7,7))\n    plt.subplot(1,2,1)\n    plt.title('Image', color = 'green', fontsize = 20)\n    plt.imshow(image)\n    plt.subplot(1,2,2)\n    plt.title('Sketches ', color = 'black', fontsize = 20)\n    plt.imshow(sketches)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:03.927073Z","iopub.execute_input":"2022-02-17T17:17:03.927406Z","iopub.status.idle":"2022-02-17T17:17:03.935834Z","shell.execute_reply.started":"2022-02-17T17:17:03.927367Z","shell.execute_reply":"2022-02-17T17:17:03.934967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls = [i for i in range(0,65,8)]\nfor i in ls:\n    plot_images(img_array[i],sketch_array[i])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:03.937348Z","iopub.execute_input":"2022-02-17T17:17:03.93777Z","iopub.status.idle":"2022-02-17T17:17:06.310101Z","shell.execute_reply.started":"2022-02-17T17:17:03.937732Z","shell.execute_reply":"2022-02-17T17:17:06.309434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dist=2000\ntrain_sketch_image = sketch_array[:dist]\ntrain_image = img_array[:dist]\ntest_sketch_image = sketch_array[dist:]\ntest_image = img_array[dist:]\n# reshaping\ntrain_sketch_image = np.reshape(train_sketch_image,(len(train_sketch_image),SIZE,SIZE,3))\ntrain_image = np.reshape(train_image, (len(train_image),SIZE,SIZE,3))\nprint('Train color image shape:',train_image.shape)\ntest_sketch_image = np.reshape(test_sketch_image,(len(test_sketch_image),SIZE,SIZE,3))\ntest_image = np.reshape(test_image, (len(test_image),SIZE,SIZE,3))\nprint('Test color image shape',test_image.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:06.31125Z","iopub.execute_input":"2022-02-17T17:17:06.312003Z","iopub.status.idle":"2022-02-17T17:17:08.879394Z","shell.execute_reply.started":"2022-02-17T17:17:06.311966Z","shell.execute_reply":"2022-02-17T17:17:08.878535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del img_array\ndel sketch_array","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:08.883312Z","iopub.execute_input":"2022-02-17T17:17:08.885362Z","iopub.status.idle":"2022-02-17T17:17:08.894103Z","shell.execute_reply.started":"2022-02-17T17:17:08.885322Z","shell.execute_reply":"2022-02-17T17:17:08.893476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def downsample(filters, size, apply_batch_normalization = True):\n    downsample = tf.keras.models.Sequential()\n    downsample.add(keras.layers.Conv2D(filters = filters, kernel_size = size, strides = 2, use_bias = False, kernel_initializer = 'he_normal'))\n    if apply_batch_normalization:\n        downsample.add(keras.layers.BatchNormalization())\n    downsample.add(keras.layers.ReLU())\n    return downsample","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:08.899286Z","iopub.execute_input":"2022-02-17T17:17:08.901524Z","iopub.status.idle":"2022-02-17T17:17:08.909419Z","shell.execute_reply.started":"2022-02-17T17:17:08.901486Z","shell.execute_reply":"2022-02-17T17:17:08.908656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upsample(filters, size, apply_dropout = False):\n    upsample = tf.keras.models.Sequential()\n    upsample.add(keras.layers.Conv2DTranspose(filters = filters, kernel_size = size, strides = 2, use_bias = False, kernel_initializer = 'he_normal'))\n    if apply_dropout:\n        upsample.add(tf.keras.layers.Dropout(0.1))\n    upsample.add(tf.keras.layers.ReLU()) \n    return upsample","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:08.914199Z","iopub.execute_input":"2022-02-17T17:17:08.917134Z","iopub.status.idle":"2022-02-17T17:17:08.925466Z","shell.execute_reply.started":"2022-02-17T17:17:08.917093Z","shell.execute_reply":"2022-02-17T17:17:08.924664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model():\n    encoder_input = keras.Input(shape = (SIZE, SIZE, 3))\n    x = downsample(16, 4, False)(encoder_input)\n    x = downsample(32,4)(x)\n    x = downsample(64,4,False)(x)\n    x = downsample(128,4)(x)\n    \n    x = downsample(256,4)(x)\n   \n    encoder_output = downsample(512,4)(x)\n    \n    decoder_input = upsample(512,4,True)(encoder_output)\n    x = upsample(256,4,False)(decoder_input)\n    x = upsample(128,4, True)(x)\n    x = upsample(64,4)(x)\n    x = upsample(32,4)(x)\n    x = upsample(16,4)(x)\n    x = tf.keras.layers.Conv2DTranspose(8,(2,2),strides = (1,1), padding = 'valid')(x)\n    decoder_output = tf.keras.layers.Conv2DTranspose(3,(2,2),strides = (1,1), padding = 'valid')(x)\n    \n  \n    return tf.keras.Model(encoder_input, decoder_output)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:08.930574Z","iopub.execute_input":"2022-02-17T17:17:08.933083Z","iopub.status.idle":"2022-02-17T17:17:08.945916Z","shell.execute_reply.started":"2022-02-17T17:17:08.933042Z","shell.execute_reply":"2022-02-17T17:17:08.945177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to get summary of model\nmodel = model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:08.950378Z","iopub.execute_input":"2022-02-17T17:17:08.953249Z","iopub.status.idle":"2022-02-17T17:17:11.746151Z","shell.execute_reply.started":"2022-02-17T17:17:08.95321Z","shell.execute_reply":"2022-02-17T17:17:11.745462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n              metrics = ['acc'])\n\nmodel.fit(train_sketch_image, train_image, epochs = 250, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:17:11.747486Z","iopub.execute_input":"2022-02-17T17:17:11.747737Z","iopub.status.idle":"2022-02-17T17:38:58.616812Z","shell.execute_reply.started":"2022-02-17T17:17:11.747703Z","shell.execute_reply":"2022-02-17T17:38:58.615626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(real,sketch, predicted):\n    plt.figure(figsize = (12,12))\n    plt.subplot(1,3,1)\n    plt.title(\"Image\",fontsize = 15, color = 'Lime')\n    plt.imshow(real)\n    plt.subplot(1,3,2)\n    plt.title(\"sketch\",fontsize = 15, color = 'Blue')\n    plt.imshow(sketch)\n    plt.subplot(1,3,3)\n    plt.title(\"Predicted\",fontsize = 15, color = 'gold')\n    plt.imshow(predicted)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:38:58.621851Z","iopub.execute_input":"2022-02-17T17:38:58.6222Z","iopub.status.idle":"2022-02-17T17:38:58.638373Z","shell.execute_reply.started":"2022-02-17T17:38:58.622161Z","shell.execute_reply":"2022-02-17T17:38:58.636525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"mask_wala_data.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:38:58.639943Z","iopub.execute_input":"2022-02-17T17:38:58.640134Z","iopub.status.idle":"2022-02-17T17:38:58.950544Z","shell.execute_reply.started":"2022-02-17T17:38:58.640109Z","shell.execute_reply":"2022-02-17T17:38:58.949811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls = [i for i in range(0,95,8)]\nfor i in ls:\n    predicted =np.clip(model.predict(test_sketch_image[i].reshape(1,SIZE,SIZE,3)),0.0,1.0).reshape(SIZE,SIZE,3)\n    show_images(test_image[i],test_sketch_image[i],predicted)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T17:38:58.954422Z","iopub.execute_input":"2022-02-17T17:38:58.955169Z","iopub.status.idle":"2022-02-17T17:39:06.458437Z","shell.execute_reply.started":"2022-02-17T17:38:58.95513Z","shell.execute_reply":"2022-02-17T17:39:06.457668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}